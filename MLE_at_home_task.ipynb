{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7npbB-a6IbIc"
      },
      "source": [
        "\n",
        "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
        "    <h1>Hello there! üëãüèª This is an at-home task for Eedi</h1>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1qtHBk_bf_f9ikBcg5QQ1i7xlM0UZv4D9\" width=\"150\" style=\"margin-right: 40px;\" />\n",
        "</div>\n",
        "\n",
        "\n",
        "Thank you for participating in this task! It is designed to assess your knowledge of knowledge graphs and negative sampling techniques. Please review the following details carefully.\n",
        "\n",
        "### Task Overview üìù\n",
        "This task consists of two parts:\n",
        "\n",
        "* Part 1: Build a ComplEx knowledge graph embedding model.\n",
        "* Part 2: Implement a Negative Sampler\n",
        "\n",
        "### Deadline ‚è∞: 27th October\n",
        "\n",
        "### Submission üì§\n",
        "\n",
        "You are required to submit two items:\n",
        "\n",
        "1. The Code\n",
        "    * Use the provided Colab notebook, to either make a copy of the notebook or download it as a .py file. Submit the `.ipynb` or `.py`file via email.\n",
        "\n",
        "2. A Video Explanation\n",
        "\n",
        "    * Record a **5-minute** video explaining your solution. Imagine you are presenting your newly developed code to a colleague. In the video, highlight the key aspects of your code, any assumptions you made, and any optimizations that are important for a teammate to understand.\n",
        "\n",
        "### Notes:\n",
        "1. We recognize that AI tools may assist you in completing this task. However, if your solution is entirely generated by an AI, it may closely resemble other candidates' submissions, making it harder for you to stand out in the process.\n",
        "\n",
        "2. The code should be able to run without requiring any highly specialized hardware. Assume that you have access to one GPU and a standard CPU.\n",
        "\n",
        "\n",
        "## Download Data: [here](https://drive.google.com/file/d/1fzwUXMnDm_JbGYvAvgReipbVasTct8XQ/view?usp=sharing)\n",
        "\n",
        "## Background KG Data üåê\n",
        "\n",
        "Graph data are represented by graph triples. A triple `(h,r,t)` consists of three parts: the `head (h)`, `relation(r)`, and `tail(t)`.\n",
        "\n",
        "Here‚Äôs a simple example:\n",
        "\n",
        "This graph:\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mKxZX0sTk584MUdyXsPT1zFKx1tLcUl9\"   width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "will be represented as the following triplet\n",
        "\n",
        "```\n",
        "Head: \"France\"\n",
        "Relation: \"hasCapital\"\n",
        "Tail: \"Paris\"\n",
        "```\n",
        "i.e. `(France, hasCapital, Paris)`\n",
        "\n",
        "\n",
        "## Dataset Overview üìä\n",
        "The given dataset represents a heterogeneous graph in which the nodes represent: _authors, books, genres, publishers, awards, and readers_. The edges represent various types of relationships between these entities, such as:\n",
        "\n",
        "* (Author, _wrote_, Book)\n",
        "* (Book, _published_by_, Publisher)\n",
        "* (Book, _belongs_to_genre_, Genre)\n",
        "* (Book, _won_award_, Award)\n",
        "* (Reader, _read_, Book)\n",
        "\n",
        "### Diagram\n",
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1QOmxWVFYLmUwfKEHKHoePdbTLbV37nCO\" width=\"600\" />\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFdWCBLKIbIe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "\n",
        "def train(\n",
        "    dataloader: DataLoader,\n",
        "    model: nn.Module,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: Optimizer,\n",
        "    device: str,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    General training loop for PyTorch models.\n",
        "    \"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        ## alter/add etc code\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    dataloader: DataLoader, model: nn.Module, device: str, k: int = 10\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    General evaluation loop for PyTorch models. Calculates hits@k.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = batch.to(device)\n",
        "            ## alter/add etc code\n",
        "            pred = model(batch)\n",
        "\n",
        "    hits = hits_at_k(ranks, k=10)\n",
        "    print(f\"hits@{k}: {hits:>7f}\")\n",
        "\n",
        "\n",
        "def hits_at_k(ranks: torch.tensor | np.array | list[int], k: int) -> torch.tensor:\n",
        "    return torch.mean((torch.tensor(ranks) <= k + 1).float())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIW8hVYIIbIf"
      },
      "source": [
        "## Part 1: ComplEx\n",
        "\n",
        "Using the provided heterogeneous book graph dataset, implement a [ComplEx](https://arxiv.org/pdf/1606.06357) knowledge graph embedding model from scratch using PyTorch. You are encouraged to optimize the model for improved performance or make any necessary enhancements.\n",
        "\n",
        "Two helper functions, `train()` and `evaluation()`, are available for you to use when training and testing your model. The functions has been intentionally left incomplete for you to customize as you see fit.\n",
        "\n",
        "**NOTE: Using them or training the model is NOT a requirement. But can be helpful to check model behaviour**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "Nb6pAXyjIbIf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpX3lL15IbIf"
      },
      "source": [
        "## Part 2: Negative Sampler\n",
        "\n",
        "In this section, we will address the challenge our model faces under the Open World Assumption: distinguishing between false facts and missing ones. To assist our model in learning this distinction, we will employ a Negative Sampling strategy. This involves generating \"corrupted\" versions of existing facts, which we will use as negative samples.\n",
        "\n",
        "\n",
        "#### Example\n",
        "Let's consider a simple example:\n",
        "\n",
        "$$\n",
        "\\mathcal{E} = \\{\\text{Mike, George, Liverpool, Manchester, London}\\}, \\\\\n",
        "\\mathcal{R} = \\{\\text{bornIn, friendsWith}\\}, \\\\\n",
        "f \\in G = \\{\\text{Mike, bornIn, Liverpool}\\}, \\\\\n",
        "$$\n",
        "\n",
        "where, $G$ is our knowledge graph with $\\mathcal{E}$, the set of entities, $\\mathcal{R}$ the set of relations  and $f$ is a true fact.\n",
        "\n",
        "If we change the tail of the fact, we can generate the following synthetic negatives:\n",
        "\n",
        "$$\n",
        "\\text{negatives} = \\begin{bmatrix}\n",
        "\\text{(Mike, bornIn, Manchester)  } \\\\\n",
        "\\text{(Mike, bornIn, George)  } \\\\\n",
        "\\text{(Mike, bornIn, London )  }\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "Some Negative Samplers can be more edge-informed, producing more relevant negatives, such as:\n",
        "\n",
        "$$\n",
        "\\text{negatives} = \\begin{bmatrix}\n",
        "\\text{(Mike, bornIn, Manchester)  } \\\\\n",
        "\\text{(Mike, bornIn, London )  }\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "## Requirements\n",
        "\n",
        "1. Implement a negative sampler that corrupts the tail entity (you are encouraged to create the data-informed version) __(code needed)__\n",
        "2. Explain how you would integrate it into the training pipeline __(text needed)__\n",
        "    * When/ Where are the negative samples going to be generated?\n",
        "    * How are they going to be used and what loss functions will you use and why?\n",
        "    * How could it affect your evaluation pipeline?\n",
        "\n",
        "You can re-use/alter any code that you previously made\n",
        "\n",
        "**NOTE: For the 2nd Requirement you do not need to implement the training code. Just provide your answer in text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ecOvDBKUIbIf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwEfaJ_-IbIf"
      },
      "source": [
        "## You've Made it to the End! üéâ\n",
        "\n",
        "Good luck, and we‚Äôre excited to see your solution! üéâ"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}