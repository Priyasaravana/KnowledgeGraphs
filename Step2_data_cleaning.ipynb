{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from CSV\n",
    "graph_details = pd.read_csv(r'data/books_graph_facts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape\n",
    "graph_details.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Handling Missing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head        0\n",
      "relation    0\n",
      "tail        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(graph_details.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Remove rows with missing values\n",
    "df_cleaned = graph_details.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Impute missing values (e.g., with the most frequent value or a placeholder)\n",
    "df_cleaned = graph_details.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:  Removing Duplicates\n",
    "Duplicate rows can introduce bias in the analysis. Here, we identify and remove all duplicate rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found:\n",
      "              head          relation           tail\n",
      "2951     book_4703  belongs_to_genre        genre_4\n",
      "4655     book_1791  belongs_to_genre       genre_18\n",
      "6048      book_346  belongs_to_genre       genre_12\n",
      "6104     book_1904  belongs_to_genre        genre_1\n",
      "6320     book_4202  belongs_to_genre        genre_1\n",
      "...            ...               ...            ...\n",
      "599950   book_3364  belongs_to_genre        genre_8\n",
      "599960   book_4017  belongs_to_genre        genre_4\n",
      "599961   book_3909  belongs_to_genre       genre_11\n",
      "599967   book_3555      published_by  publisher_120\n",
      "599983  reader_368              read      book_2938\n",
      "\n",
      "[36705 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find and display all duplicate rows in the DataFrame\n",
    "duplicates = graph_details[graph_details.duplicated()]\n",
    "\n",
    "# Check if there are any duplicates, and then display them\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates found:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df_cleaned = graph_details.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>book_4703</td>\n",
       "      <td>belongs_to_genre</td>\n",
       "      <td>genre_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           head          relation     tail\n",
       "2803  book_4703  belongs_to_genre  genre_4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[(df_cleaned['head'] == 'book_4703') & (df_cleaned['relation'] == 'belongs_to_genre') & (df_cleaned['tail'] == 'genre_4')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:  To ensure data consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head        object\n",
      "relation    object\n",
      "tail        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the data types of all columns in the DataFrame\n",
    "print(df_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Data Consistency: Ensuring Consistent Naming\n",
    "To avoid inconsistencies, this step standardizes all text data to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book_3725</td>\n",
       "      <td>won_award</td>\n",
       "      <td>award_85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book_1435</td>\n",
       "      <td>published_by</td>\n",
       "      <td>publisher_152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author_944</td>\n",
       "      <td>wrote</td>\n",
       "      <td>book_3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reader_4577</td>\n",
       "      <td>read</td>\n",
       "      <td>book_2631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book_1633</td>\n",
       "      <td>belongs_to_genre</td>\n",
       "      <td>genre_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>reader_3389</td>\n",
       "      <td>read</td>\n",
       "      <td>book_3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>book_1968</td>\n",
       "      <td>belongs_to_genre</td>\n",
       "      <td>genre_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>reader_1680</td>\n",
       "      <td>read</td>\n",
       "      <td>book_4606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>book_4405</td>\n",
       "      <td>won_award</td>\n",
       "      <td>award_35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>reader_2685</td>\n",
       "      <td>read</td>\n",
       "      <td>book_4028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563295 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               head          relation           tail\n",
       "0         book_3725         won_award       award_85\n",
       "1         book_1435      published_by  publisher_152\n",
       "2        author_944             wrote      book_3099\n",
       "3       reader_4577              read      book_2631\n",
       "4         book_1633  belongs_to_genre       genre_11\n",
       "...             ...               ...            ...\n",
       "599995  reader_3389              read      book_3783\n",
       "599996    book_1968  belongs_to_genre       genre_10\n",
       "599997  reader_1680              read      book_4606\n",
       "599998    book_4405         won_award       award_35\n",
       "599999  reader_2685              read      book_4028\n",
       "\n",
       "[563295 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing text data to lowercase for consistency\n",
    "df_cleaned = df_cleaned.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Outlier Detection: Detecting and Handling Outliers - Identifying Entities with Unusual Relations\n",
    "Using Z-scores, this section identifies entities with abnormally high or low relationships, which may indicate anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the degree of each entity (how many relations it participates in)\n",
    "entity_degrees = pd.concat([df_cleaned['head'], df_cleaned['tail']]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores to detect outliers (outliers in entity connectivity)\n",
    "mean_degree = np.mean(entity_degrees)\n",
    "std_degree = np.std(entity_degrees)\n",
    "z_scores = (entity_degrees - mean_degree) / std_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for outliers (e.g., Z-score > 3 or < -3)\n",
    "outliers = entity_degrees[(z_scores.abs() > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities with unusually high or low number of relations (outliers):\n",
      "genre_3      2942\n",
      "genre_19     2926\n",
      "genre_12     2912\n",
      "genre_15     2907\n",
      "genre_13     2897\n",
      "             ... \n",
      "award_116     508\n",
      "award_42      507\n",
      "award_118     501\n",
      "award_87      501\n",
      "award_134     498\n",
      "Name: count, Length: 169, dtype: int64\n",
      "          head      relation           tail  is_outlier\n",
      "1    book_1435  published_by  publisher_152       False\n",
      "2   author_944         wrote      book_3099       False\n",
      "3  reader_4577          read      book_2631       False\n",
      "5  reader_2664          read       book_252       False\n",
      "6   reader_444          read       book_319       False\n"
     ]
    }
   ],
   "source": [
    "# Display the outliers\n",
    "print(\"Entities with unusually high or low number of relations (outliers):\")\n",
    "print(outliers)\n",
    "\n",
    "# Option 1: Flag outliers by creating a separate column in the DataFrame\n",
    "df_cleaned['is_outlier'] = df_cleaned['head'].isin(outliers.index) | df_cleaned['tail'].isin(outliers.index)\n",
    "\n",
    "# Option 2: Remove the outliers directly\n",
    "df_cleaned = df_cleaned[~df_cleaned['head'].isin(outliers.index) & ~df_cleaned['tail'].isin(outliers.index)]\n",
    "\n",
    "# Verify the cleaned DataFrame\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424775, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the original DataFrame with the cleaned one\n",
    "df = df_cleaned\n",
    "\n",
    "# Optionally, save the cleaned DataFrame to a new file\n",
    "df.to_csv('cleaned_books_graph_facts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
