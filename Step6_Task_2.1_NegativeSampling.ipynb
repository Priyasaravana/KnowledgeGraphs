{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          head          relation           tail\n",
      "0    book_3725         won_award       award_85\n",
      "1    book_1435      published_by  publisher_152\n",
      "2   author_944             wrote      book_3099\n",
      "3  reader_4577              read      book_2631\n",
      "4    book_1633  belongs_to_genre       genre_11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/books_graph_facts.csv')\n",
    "\n",
    "# Ensure the columns are named 'head', 'relation', 'tail'\n",
    "df.columns = ['head', 'relation', 'tail']\n",
    "\n",
    "# Display first few rows to confirm\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with pykeen\n",
    "* pykeen.pipeline.pipeline() - To train and evaluate the model\n",
    "* pykeen.models - Provide list of supported models \n",
    "* pykeen.datasets - Load the dataset\n",
    "* pykeen.training - Model can be trained under stochastic local closed world assumption (LCWA)\n",
    "* pykeen.sampling - to negative sample options like Basic, Bernoulli\n",
    "* pykeen.evaluation - evaluate the model and returns the MetricResults (default - RankBasedEvaluator)\n",
    "* stopper - early stopping of training the model\n",
    "* Learning rate - lr_schedule_kwargs - to schedule the leanring rate with gamma params\n",
    "* Triples - Classes for creating and storing training data from triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=1127245888\n"
     ]
    }
   ],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# Convert the dataset to a triples array (head, relation, tail)\n",
    "triples = df[['head', 'relation', 'tail']].values\n",
    "\n",
    "# Create a TriplesFactory from the triples\n",
    "triples_factory = TriplesFactory.from_labeled_triples(triples)\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "training, testing, validation = triples_factory.split([0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Negative Sampling with Pykeen\n",
    "\n",
    "- Uniform Negative sampling - Randomly corrupts either Head or Tail.  \n",
    "\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(corruption_scheme=('h', 'r', 't'))  # Inform which corruption methods are used\n",
    "- Bernoulli Negative Sampling - Based on the probability (pr or (1-pr))  \n",
    "\n",
    "        negative_sampler='bernoulli'\n",
    "- Identify False negatives during training  \n",
    "\n",
    "        negative_sampler='basic',\n",
    "        \n",
    "        negative_sampler_kwargs=dict(filtered=True) # to filter False negatives from sampling\n",
    "\n",
    "        negative_sampler_kwargs=dict(filtered=True, filterer='bloom', \n",
    "                filterer_kwargs=dict(error_rate=0.0001)) # decreading the error rate will increase the computation cost.\n",
    "\n",
    "        negative_sampler_kwargs=dict(filtered=True,\n",
    "                filterer='python-set') # Guarantees that false negatives are filtered \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1 implmentation: Usage of basic negative sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cuda:0: 100%|██████████| 100/100 [11:47<00:00,  7.08s/epoch, loss=0.0329, prev_loss=0.0329]\n",
      "Evaluating on cuda:0: 100%|██████████| 56.3k/56.3k [00:53<00:00, 1.05ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 106.11s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10: 0.029\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# Set up parameters for the pipeline\n",
    "model_name = 'RotatE'  # You can change this to other models like TransE, ComplEx, etc.\n",
    "epochs = 100  # Number of epochs to train\n",
    "seed = 42  # Set random seed for reproducibility\n",
    "\n",
    "# Train the model using the pipeline\n",
    "result = pipeline(\n",
    "    training=training,       # Training set\n",
    "    testing=testing,         # Testing set\n",
    "    validation=validation,   # Validation set\n",
    "    model=model_name,        # Model name\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=epochs,   # Training epochs\n",
    "        use_tqdm_batch=False  # Disable tqdm progress bar for batches\n",
    "    ),\n",
    "    random_seed=seed,        # Set random seed\n",
    "    negative_sampler='basic'  # Specify the negative sampler (basic, bernoulli, etc.)\n",
    ")\n",
    "\n",
    "# Print the final evaluation result (Hits@10 is used as an example metric)\n",
    "hits_at_10 = result.metric_results.get_metric(\"hits_at_10\")\n",
    "print(f\"Hits@10: {hits_at_10:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.triples.triples_factory:Stored TriplesFactory(num_entities=11570, num_relations=5, create_inverse_triples=False, num_triples=450636) to file:///C:/Users/EzhilPriyadharshiniK/OneDrive%20-%20Infoseck2k/Documents/Priya/Code/KnowledgeGraphs/model/training_triples\n",
      "INFO:pykeen.pipeline.api:Saved to directory: C:\\Users\\EzhilPriyadharshiniK\\OneDrive - Infoseck2k\\Documents\\Priya\\Code\\KnowledgeGraphs\\model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory where you want to save the model\n",
    "save_dir = './model/'\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Save the model, results, and metadata to the directory\n",
    "result.save_to_directory(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2 implmentation: Usage of basic negative sampler with filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cuda:0: 100%|██████████| 100/100 [59:30<00:00, 35.70s/epoch, loss=0.0137, prev_loss=0.0138]  \n",
      "Evaluating on cuda:0: 100%|██████████| 56.3k/56.3k [00:58<00:00, 966triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 90.38s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10: 0.022\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# Set up parameters for the pipeline\n",
    "model_name = 'RotatE'  # You can change this to other models like TransE, ComplEx, etc.\n",
    "epochs = 100  # Number of epochs to train\n",
    "seed = 42  # Set random seed for reproducibility\n",
    "\n",
    "# Train the model using the pipeline\n",
    "result = pipeline(\n",
    "    training=training,       # Training set\n",
    "    testing=testing,         # Testing set\n",
    "    validation=validation,   # Validation set\n",
    "    model=model_name,        # Model name\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=epochs,   # Training epochs\n",
    "        use_tqdm_batch=False  # Disable tqdm progress bar for batches\n",
    "    ),\n",
    "    random_seed=seed,        # Set random seed\n",
    "    negative_sampler='basic',  # Specify the negative sampler (basic, bernoulli, etc.)\n",
    "    negative_sampler_kwargs=dict(\n",
    "        filtered=True,\n",
    "        filterer='python-set',    \n",
    "    ),\n",
    ")\n",
    "\n",
    "# Print the final evaluation result (Hits@10 is used as an example metric)\n",
    "hits_at_10 = result.metric_results.get_metric(\"hits_at_10\")\n",
    "print(f\"Hits@10: {hits_at_10:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3 implmentation: Usage of basic negative sampler. To perform the corruption just on tail along with data informed sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cuda:0: 100%|██████████| 100/100 [13:51<00:00,  8.32s/epoch, loss=0.00676, prev_loss=0.00682]\n",
      "Evaluating on cuda:0: 100%|██████████| 56.3k/56.3k [01:02<00:00, 905triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 108.79s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10: 0.054\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# Set up parameters for the pipeline\n",
    "model_name = 'RotatE'  # You can change this to other models like TransE, ComplEx, etc.\n",
    "epochs = 100  # Number of epochs to train\n",
    "seed = 42  # Set random seed for reproducibility\n",
    "\n",
    "# Train the model using the pipeline\n",
    "result = pipeline(\n",
    "    training=training,       # Training set\n",
    "    testing=testing,         # Testing set\n",
    "    validation=validation,   # Validation set\n",
    "    model=model_name,        # Model name\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=epochs,   # Training epochs\n",
    "        use_tqdm_batch=False  # Disable tqdm progress bar for batches\n",
    "    ),\n",
    "    random_seed=seed,        # Set random seed\n",
    "    negative_sampler='basic',  # Specify the negative sampler (basic, bernoulli, etc.)\n",
    "    negative_sampler_kwargs=dict(\n",
    "        corruption_scheme=['tail'], # corrupt the tail\n",
    "        filtered=True,\n",
    "        filterer='python-set',    \n",
    "    ),\n",
    ") \n",
    "\n",
    "# Print the final evaluation result (Hits@10 is used as an example metric)\n",
    "hits_at_10 = result.metric_results.get_metric(\"hits_at_10\")\n",
    "print(f\"Hits@10: {hits_at_10:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
